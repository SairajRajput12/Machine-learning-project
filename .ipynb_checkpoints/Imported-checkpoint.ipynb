{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b187a679-56d4-4bd2-8f9c-a3a6b1c0b6ee",
   "metadata": {},
   "source": [
    "## Code for action recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d4a433c-bc0b-4e75-8c22-ddeb2005c214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nose_X    nose_Y    nose_Z    nose_V  left_eye_inner_X  left_eye_inner_Y  \\\n",
      "0 -0.26861 -0.458431  0.328992  0.999988         -0.260716         -0.488644   \n",
      "\n",
      "   left_eye_inner_Z  left_eye_inner_V  left_eye_X  left_eye_Y  ...  \\\n",
      "0          0.253323          0.999979   -0.256325    -0.49046  ...   \n",
      "\n",
      "   right_heel_Z  right_heel_V  left_foot_index_X  left_foot_index_Y  \\\n",
      "0      0.336425      0.988631           0.512082           0.486277   \n",
      "\n",
      "   left_foot_index_Z  left_foot_index_V  right_foot_index_X  \\\n",
      "0          -0.475314           0.997432           -0.352852   \n",
      "\n",
      "   right_foot_index_Y  right_foot_index_Z  right_foot_index_V  \n",
      "0            0.575511            0.301457             0.98793  \n",
      "\n",
      "[1 rows x 132 columns]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "`tf.data.Dataset` only supports Python-style iteration in eager mode or within tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 73\u001b[0m\n\u001b[0;32m     69\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([np\u001b[38;5;241m.\u001b[39marray(pre_lm)\u001b[38;5;241m.\u001b[39mflatten()], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m     70\u001b[0m                                                             \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m landmark_names \n\u001b[0;32m     71\u001b[0m                                                             \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m---> 73\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(predict) \u001b[38;5;241m>\u001b[39m threshold:\n\u001b[0;32m     76\u001b[0m     pose_class \u001b[38;5;241m=\u001b[39m class_names[np\u001b[38;5;241m.\u001b[39margmax(predict)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:503\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator_ops\u001b[38;5;241m.\u001b[39mOwnedIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: `tf.data.Dataset` only supports Python-style iteration in eager mode or within tf.function."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.models import load_model\n",
    "\n",
    "source = \"Running1.jpg\"\n",
    "path_saved_model = \"Models/Action Recognition/model.keras\"\n",
    "threshold = 0.2\n",
    "save = \"Output\"\n",
    "\n",
    "torso_size_multiplier = 2.5\n",
    "n_landmarks = 33\n",
    "landmark_names = [\n",
    "    'nose',\n",
    "    'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
    "    'right_eye_inner', 'right_eye', 'right_eye_outer',\n",
    "    'left_ear', 'right_ear',\n",
    "    'mouth_left', 'mouth_right',\n",
    "    'left_shoulder', 'right_shoulder',\n",
    "    'left_elbow', 'right_elbow',\n",
    "    'left_wrist', 'right_wrist',\n",
    "    'left_pinky_1', 'right_pinky_1',\n",
    "    'left_index_1', 'right_index_1',\n",
    "    'left_thumb_2', 'right_thumb_2',\n",
    "    'left_hip', 'right_hip',\n",
    "    'left_knee', 'right_knee',\n",
    "    'left_ankle', 'right_ankle',\n",
    "    'left_heel', 'right_heel',\n",
    "    'left_foot_index', 'right_foot_index',\n",
    "]\n",
    "class_names = ['Running', 'Standing', 'Walking', 'Waving']\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Load saved model\n",
    "model = load_model(path_saved_model, compile=True)\n",
    "\n",
    "# Load sample Image\n",
    "img = cv2.imread(source)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "result = pose.process(img_rgb)\n",
    "\n",
    "if result.pose_landmarks:\n",
    "    lm_list = []\n",
    "    for landmarks in result.pose_landmarks.landmark:\n",
    "        lm_list.append(landmarks)\n",
    "\n",
    "    center_x = (lm_list[landmark_names.index('right_hip')].x +\n",
    "                lm_list[landmark_names.index('left_hip')].x) * 0.5\n",
    "    center_y = (lm_list[landmark_names.index('right_hip')].y +\n",
    "                lm_list[landmark_names.index('left_hip')].y) * 0.5\n",
    "\n",
    "    max_distance = max(math.sqrt((lm.x - center_x) ** 2 + (lm.y - center_y) ** 2) \n",
    "                       for lm in lm_list)\n",
    "    torso_size = math.sqrt((lm_list[landmark_names.index('right_shoulder')].x - center_x) ** 2 +\n",
    "                           (lm_list[landmark_names.index('right_shoulder')].y - center_y) ** 2)\n",
    "    max_distance = max(torso_size * torso_size_multiplier, max_distance)\n",
    "\n",
    "    pre_lm = [[(lm.x - center_x) / max_distance, \n",
    "               (lm.y - center_y) / max_distance,\n",
    "               lm.z / max_distance,\n",
    "               lm.visibility] for lm in lm_list]\n",
    "\n",
    "    data = pd.DataFrame([np.array(pre_lm).flatten()], columns=[f'{name}_{attr}' \n",
    "                                                                for name in landmark_names \n",
    "                                                                for attr in ['X', 'Y', 'Z', 'V']])\n",
    "    print(data)\n",
    "    predict = model.predict(data)[0]\n",
    "\n",
    "    if max(predict) > threshold:\n",
    "        pose_class = class_names[np.argmax(predict)]\n",
    "        print('Predictions:', predict)\n",
    "        print('Predicted Pose Class:', pose_class)\n",
    "    else:\n",
    "        pose_class = 'Unknown Pose'\n",
    "        print('Predictions is below given Confidence!!')\n",
    "else:\n",
    "    pose_class = 'No Pose Detected'\n",
    "\n",
    "print('Predicted Pose Class:', pose_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83f040ae-49ec-460a-838f-24abb149388b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (C:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m TrainingImagePath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/Train\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Understand more about ImageDataGenerator at below link\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# of the original image, which leads to a better model, since it learns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# on the good and bad mix of images\u001b[39;00m\n\u001b[0;32m     11\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m     12\u001b[0m         shear_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     13\u001b[0m         zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     14\u001b[0m         horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (C:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)"
     ]
    }
   ],
   "source": [
    "TrainingImagePath='/data/Train'\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Understand more about ImageDataGenerator at below link\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "# Defining pre-processing transformations on raw images of training data\n",
    "# These hyper parameters helps to generate slightly twisted versions\n",
    "# of the original image, which leads to a better model, since it learns\n",
    "# on the good and bad mix of images\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Defining pre-processing transformations on raw images of testing data\n",
    "# No transformations are done on the testing images\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# Generating the Training Data\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "# Generating the Testing Data\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Printing class labels for each face\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b85ef-0b2e-4139-b208-dcd9df68d37c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
